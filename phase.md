# Development Phases

## Phase 1 - Data Layer (Scraper & Data Preparation)
**Status**: ‚úÖ Completed
**Files**:
- `data/scraper/scrape_sfgc.py` - Scrapes public pages of sfgc.ac.in
- `data/scraper/page_parser.py` - Cleans scraped HTML text
- `data/scraper/intent_mapper.py` - Converts website text into chatbot intents
- `data/raw/scraped_sfgc_data.json` - Raw text scraped from website
- `data/processed/sfgc_intents.json` - Clean, ML-ready training dataset

**Purpose**: Extract and process data from the SFGC website to create a training dataset

---

## Phase 2 - NLP Pipeline
**Status**: ‚úÖ Completed
**Files**:
- `backend/nlp/preprocess.py` - Cleans input text (lowercase, remove symbols)
- `backend/nlp/tokenizer.py` - Splits sentences into words
- `backend/nlp/lemmatizer.py` - Converts words to base form (running ‚Üí run)

**Purpose**: Process raw text input for ML model consumption

---

## Phase 3 - ML Model (Training & Prediction)
**Status**: ‚úÖ Completed
**Files**:
- `backend/pipeline/data_loader.py` - Loads processed training data
- `backend/pipeline/feature_engineering.py` - Converts text to TF-IDF vectors
- `backend/ml/train.py` - Trains ML intent classification model
- `backend/ml/predict.py` - Predicts intent + confidence score
- `backend/models/intent_model.pkl` - Trained ML model (generated)
- `backend/models/vectorizer.pkl` - TF-IDF vectorizer (generated)

**Purpose**: Build and train intent classification model

---

## Phase 4 - Knowledge Base & Response Selection
**Status**: ‚úÖ Completed
**Files**:
- `backend/knowledge_base/sfgc_intents.json` - Final training dataset (intent + patterns + response)
- `backend/knowledge_base/responses.py` - Maps intent ‚Üí official answer
- `backend/knowledge_base/fallback.json` - Safe replies when confidence is low
- `backend/pipeline/response_selector.py` - Chooses final response or fallback
- `backend/pipeline/confidence.py` - Checks confidence threshold

**Purpose**: Define knowledge base and select appropriate responses based on confidence

---

## Phase 5 - API & Backend Infrastructure
**Status**: ‚úÖ Completed
**Files**:
- `backend/config.py` - Global configurations (confidence threshold, paths)
- `backend/database.py` - Optional SQLite setup for logs
- `backend/utils/logger.py` - Logging helper
- `backend/utils/helpers.py` - Common utility functions
- `backend/api/health.py` - Simple endpoint to check if backend is running
- `backend/api/chat_api.py` - Receives user question and returns chatbot response
- `backend/main.py` - Entry point of FastAPI server

**Purpose**: Build FastAPI backend with API endpoints and infrastructure

---

## Phase 6 - Frontend UI
**Status**: ‚úÖ Completed
**Files**:
- `frontend/app.py` - Streamlit chatbot UI
- `frontend/ui_components.py` - UI helper components

**Purpose**: Create user interface for chatbot interaction

---

## Phase 7 - Testing, Requirements & Deployment
**Status**: Pending
**Files**:
- `tests/test_scraper.py` - Tests scraping logic
- `tests/test_nlp.py` - Tests NLP preprocessing
- `tests/test_ml.py` - Tests ML predictions
- `tests/test_api.py` - Tests backend endpoints
- `requirements.txt` - All Python dependencies
- `README.md` - Project overview, setup steps, run instructions
- `run.bat` - Windows batch file to run scraping ‚Üí training ‚Üí backend ‚Üí UI

**Purpose**: Ensure code quality, document setup, and enable deployment

---

## Phase 8 - ML Operations (Optional)
**Status**: Pending
**Files**:
- `backend/ml/evaluator.py` - Evaluates accuracy, precision
- `backend/ml/retrain.py` - Retrains model using new data
- `backend/logs/chat_logs.txt` - Stores all user‚Äìbot conversations
- `backend/logs/low_confidence_queries.json` - Stores unclear questions for learning

**Purpose**: Monitor model performance and enable continuous improvement

---

## Completion Summary

### ‚úÖ Completed Phases (6/8)
1. **Phase 1** - Data Layer ‚úÖ
2. **Phase 2** - NLP Pipeline ‚úÖ
3. **Phase 3** - ML Model ‚úÖ
4. **Phase 4** - Knowledge Base & Response ‚úÖ
5. **Phase 5** - API & Backend Infrastructure ‚úÖ
6. **Phase 6** - Frontend UI ‚úÖ

### ‚è≥ Pending Phases (2/8)
7. **Phase 7** - Testing, Requirements & Deployment
8. **Phase 8** - ML Operations (Optional)

### üèóÔ∏è Phase 5 Implementation Details
**API Endpoints**:
- `GET /health/status` - Health check
- `GET /health/stats` - Chatbot statistics
- `GET /health/config` - API configuration
- `POST /chat/ask` - Main chatbot endpoint
- `GET /chat/logs` - Chat history
- `GET /chat/intents` - Available intents

**Backend Components**:
- **config.py** - Settings management with Pydantic
- **database.py** - SQLite logging (chat_logs, low_confidence_queries)
- **logger.py** - Rotating file logger
- **helpers.py** - Response formatting, query validation, utilities
- **health.py** - Health check endpoints
- **chat_api.py** - Chat processing pipeline
- **main.py** - FastAPI app with CORS middleware

### üì± Phase 6 Implementation Details
**Streamlit Features**:
- Real-time chat interface
- Message history with intent/confidence display
- Statistics dashboard (total chats, low confidence queries, avg confidence)
- Quick action buttons (Courses, Admissions, About)
- Backend health status indicator
- Available intents sidebar display
- Response source tracking (Knowledge Base vs Fallback)

**UI Components**:
- Chat message display with role distinction
- Confidence badges with emoji levels
- Intent cards with metrics
- Statistics dashboard
- Error/Success/Info message display
- Clear chat history button

### üì¶ Dependencies
All required dependencies have been installed successfully from `requirements.txt`:
- **FastAPI, Uvicorn** (Web Framework)
- **Streamlit** (Frontend)
- **Scikit-learn, Pandas, NumPy** (ML)
- **BeautifulSoup4** (Web Scraping)
- **Pytest** (Testing)
- **Pydantic** (Data validation)

---

## üöÄ Running the Application

### Backend (FastAPI)
```bash
cd backend
python main.py
# Or using uvicorn directly:
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```
The API will be available at `http://localhost:8000`
- API Docs: `http://localhost:8000/docs`
- Health Check: `http://localhost:8000/health/status`

### Frontend (Streamlit)
```bash
cd frontend
streamlit run app.py
```
The UI will be available at `http://localhost:8501`

### Running Both Together
Use the `run.bat` script (Windows):
```bash
run.bat
```

---

## Data Flow Diagram
```
scrape_sfgc.py
    ‚Üì
scraped_sfgc_data.json
    ‚Üì
page_parser.py
    ‚Üì
intent_mapper.py
    ‚Üì
sfgc_intents.json (processed)
    ‚Üì
data_loader.py
    ‚Üì
feature_engineering.py (TF-IDF)
    ‚Üì
train.py
    ‚Üì
intent_model.pkl + vectorizer.pkl
    ‚Üì
predict.py ‚Üí confidence.py
    ‚Üì
response_selector.py
    ‚Üì
chat_api.py
    ‚Üì
app.py (Frontend)
```
